{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "freesound_audio_tagging.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "asJgSN12CYcS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget -O FSDKaggle2018.audio_train.zip https://zenodo.org/record/2552860/files/FSDKaggle2018.audio_train.zip?download=1\n",
        "!wget -O FSDKaggle2018.audio_test.zip https://zenodo.org/record/2552860/files/FSDKaggle2018.audio_test.zip?download=1\n",
        "!wget -O FSDKaggle2018.meta.zip https://zenodo.org/record/2552860/files/FSDKaggle2018.meta.zip?download=1\n",
        "!unzip \\*.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "svsXuRVq2y8W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir data submission\n",
        "%mv FSDKaggle2018.audio_train data/train\n",
        "%mv FSDKaggle2018.audio_test data/test\n",
        "%mv -v FSDKaggle2018.meta/* submission/\n",
        "%cd data/train/\n",
        "!ls -F |grep -v / | wc -l\n",
        "%cd ../test/\n",
        "!ls -F |grep -v / | wc -l\n",
        "%cd ../..\n",
        "!rm FSDKaggle2018.audio_train.zip FSDKaggle2018.audio_test.zip FSDKaggle2018.meta.zip\n",
        "!rm -R FSDKaggle2018.meta"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eeY5NETN0gpc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget -O summary_feats_funcs.py https://drive.google.com/open?id=1BEXV2BN9il2_O1L-uGPYGnTJKnOZjzJz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ri6K7y0j_YCy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!find . -name \"*.wav\" -type f -delete"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kyMYcIS2DsMT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import librosa\n",
        "import os\n",
        "import re\n",
        "import sys\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn import  preprocessing\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from sklearn.model_selection import GridSearchCV, train_test_split\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.layers import Dense, Embedding, LSTM, GRU, Bidirectional\n",
        "from tensorflow.keras.layers import Conv1D, Conv2D, GlobalMaxPooling1D\n",
        "from tensorflow.keras.layers import Activation, Flatten, Dropout\n",
        "from tensorflow.keras.models import Sequential,model_from_json\n",
        "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
        "\n",
        "import keras \n",
        "\n",
        "from keras import regularizers\n",
        "from keras import backend as K\n",
        "\n",
        "from keras.activations import relu, softmax\n",
        "from keras.layers import Input, InputLayer, Dense,Flatten,Dropout,Activation, BatchNormalization, Conv1D, GlobalAveragePooling1D, MaxPool1D, GlobalMaxPooling1D, LSTM\n",
        "from keras.layers.merge import add\n",
        "from keras.models import Sequential, Model\n",
        "from keras.utils import to_categorical\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "\n",
        "from joblib import Parallel, delayed\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "import pickle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6LkSQHIEx7Qi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sys.path.append('/content')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QES1AKZSDEPk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install pushbullet.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GPoOFT-lCYce",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "df_train_og = pd.read_csv(\"/content/submission/train_post_competition.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lmPL-tToGcZP",
        "colab_type": "text"
      },
      "source": [
        "## 1. Pre-process"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AuB3dgYQGcyq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"Pre-process\"\"\"\n",
        "\n",
        "sampling_rate = 44100\n",
        "\n",
        "#train = pd.read_csv(\"data/train.csv\")\n",
        "train = df_train_og\n",
        "samp_subm = df_train_og[[\"fname\"]].copy()\n",
        "samp_subm['label'] = \"\"\n",
        "\n",
        "# Ignoring the empty wavs\n",
        "samp_subm['toremove'] = 0\n",
        "samp_subm.loc[samp_subm.fname.isin([\n",
        "    '0b0427e2.wav', '6ea0099f.wav', 'b39975f5.wav'\n",
        "]), 'toremove'] = 1\n",
        "\n",
        "# print('Train...')\n",
        "# os.makedirs('data/audio_train_trim/', exist_ok=True)\n",
        "# for filename in tqdm(train.fname.values):\n",
        "#     x, sr = librosa.load('data/audio_train/' + filename, sampling_rate)\n",
        "#     x = librosa.effects.trim(x)[0]\n",
        "#     np.save('data/audio_train_trim/' + filename + '.npy', x)\n",
        "\n",
        "print('Test...')\n",
        "os.makedirs('data/audio_test_trim/', exist_ok=True)\n",
        "for filename in tqdm(samp_subm.loc[lambda x: x.toremove == 0, :].fname.values):\n",
        "    x, sr = librosa.load('data/train/' + filename, sampling_rate)\n",
        "    x = librosa.effects.trim(x)[0]\n",
        "    np.save('data/audio_test_trim/' + filename + '.npy', x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1_8zbdA1HvDz",
        "colab_type": "text"
      },
      "source": [
        "## 2. Compute Log-Mel"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LY-3yu4V-rRm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"Compute Log Mel-Spectrograms\"\"\"\n",
        "# calculate log mel: https://datascience.stackexchange.com/questions/27634/how-to-convert-a-mel-spectrogram-to-log-scaled-mel-spectrogram\n",
        "# Paper: https://arxiv.org/pdf/1608.04363.pdf\n",
        "\n",
        "\n",
        "\n",
        "sampling_rate = 44100\n",
        "\n",
        "train = df_train_og\n",
        "samp_subm = df_train_og[[\"fname\"]].copy()\n",
        "samp_subm['label'] = \"\"\n",
        "\n",
        "# Ignoring the empty wavs\n",
        "# samp_subm['toremove'] = 0\n",
        "# samp_subm.loc[samp_subm.fname.isin([\n",
        "#     '0b0427e2.wav', '6ea0099f.wav', 'b39975f5.wav'\n",
        "# ]), 'toremove'] = 1\n",
        "\n",
        "\n",
        "def compute_melspec(filename, indir, outdir):\n",
        "    wav = np.load(indir + filename + '.npy')\n",
        "    wav = librosa.resample(wav, 44100, 22050)\n",
        "    melspec = librosa.feature.melspectrogram(wav,\n",
        "                                             sr=22050,\n",
        "                                             n_fft=1764,\n",
        "                                             hop_length=220,\n",
        "                                             n_mels=64)\n",
        "    logmel = librosa.core.power_to_db(melspec)\n",
        "    np.save(outdir + filename + '.npy', logmel)\n",
        "\n",
        "\n",
        "# print('Train...')\n",
        "# os.makedirs('/data/mel_spec_train', exist_ok=True)\n",
        "# for x in tqdm(train.fname.values):\n",
        "#     compute_melspec(x, 'data/audio_train_trim/', 'data/mel_spec_train/')\n",
        "\n",
        "print('Test...')\n",
        "os.makedirs('data/mel_spec_test/', exist_ok=True)\n",
        "for x in tqdm(samp_subm.loc[lambda x: x.toremove == 0, :].fname.values):\n",
        "    compute_melspec(x, 'data/audio_test_trim/', 'data/mel_spec_test/')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QkjitSKGHzB0",
        "colab_type": "text"
      },
      "source": [
        "## 3. Compute Summary metrics of various spectral and time based features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j4wEuLyhEWXo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# number of cores to use\n",
        "num_cores = 1\n",
        "\n",
        "# print('Train...')\n",
        "# train = pd.read_csv('data/train.csv')\n",
        "\n",
        "# train_feats = Parallel(n_jobs=num_cores)(\n",
        "#     delayed(all_feats)('data/audio_train_trim/' + x + '.npy')\n",
        "#     for x in tqdm(train.fname.values))\n",
        "\n",
        "# train_feats_df = pd.DataFrame(np.vstack(train_feats))\n",
        "# train_feats_df['fname'] = pd.Series(train.fname.values, index=train_feats_df.index)\n",
        "# train_feats_df.to_pickle('data/train_tab_feats.pkl')\n",
        "\n",
        "\n",
        "print('Test...')\n",
        "# samp_subm = pd.read_csv(\"data/sample_submission.csv\")\n",
        "# samp_subm['toremove'] = 0\n",
        "# samp_subm.loc[samp_subm.fname.isin([\n",
        "#     '0b0427e2.wav', '6ea0099f.wav', 'b39975f5.wav'\n",
        "# ]), 'toremove'] = 1\n",
        "\n",
        "\n",
        "test_feats = Parallel(n_jobs=num_cores)(\n",
        "    delayed(all_feats)('data/audio_test_trim/' + x + '.npy')\n",
        "    for x in tqdm(samp_subm\n",
        "                  .loc[lambda x: x.toremove == 0, :]\n",
        "                  .fname.values))\n",
        "\n",
        "test_feats_df = pd.DataFrame(np.vstack(test_feats))\n",
        "test_feats_df['fname'] = pd.Series(samp_subm.loc[lambda x: x.toremove == 0, :].fname.values,\n",
        "                                   index=test_feats_df.index)\n",
        "test_feats_df.to_pickle('data/test_tab_feats.pkl')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VysKVEOwCYch",
        "colab_type": "text"
      },
      "source": [
        "## Get files from original"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KpuLfufbCYch",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "file_to_tag = pd.Series(df_train_og['label'].values,index=df_train_og['fname']).to_dict()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fp4MP8HJCYck",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def getTag(x):\n",
        "    return (file_to_tag[x])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FW4PCAOACYcm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# function Clickconnect() {\n",
        "#   console.log('Working')\n",
        "#   document\n",
        "#     .querySelector('#top-toolbar > colab-connect-button')\n",
        "#     .shadowRoot.querySelector('#connect')\n",
        "#     .click()\n",
        "# }\n",
        "\n",
        "# setInterval(Clickconnect, 60000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d_CNzBAECYcp",
        "colab_type": "text"
      },
      "source": [
        "## Import Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LWRW9YbpCYcp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "\n",
        "pickle_in = open(\"train_tab_feats.pkl\",\"rb\")\n",
        "df_train = pickle.load(pickle_in)\n",
        "\n",
        "pickle_in = open(\"test_tab_feats.pkl\",\"rb\")\n",
        "df_test = pickle.load(pickle_in)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eHE2YjvHCYcr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "total = pd.concat([df_train,df_test],ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9YuopDgACYcu",
        "colab_type": "text"
      },
      "source": [
        "#### Need usable test file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WFbHFpZxCYcu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#total['tag'] = total['fname'].apply(getTag)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P8MWfxJaCYcx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xF_UMdbSCYcz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train['tag'] = df_train['fname'].apply(getTag)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wfnQaiiKCYc1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train_copy = df_train.drop(['fname','tag'], axis = 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-7O559J8CYc3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S2D62t_9CYc5",
        "colab_type": "text"
      },
      "source": [
        "## Reduce Dimensions and Make Train Val Sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8As13FIsCYc5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LDA = LinearDiscriminantAnalysis()\n",
        "X = LDA.fit_transform(df_train_copy, df_train['tag'])\n",
        "\n",
        "x_train, x_val, y_train, y_val = train_test_split(X,  df_train['tag'], shuffle = True, test_size = 0.2, random_state = 42)\n",
        "\n",
        "encoder = preprocessing.LabelEncoder()\n",
        "y_train = encoder.fit_transform(y_train)\n",
        "y_val = encoder.fit_transform(y_val)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ezEkTM5TCYc8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TSmNEg4JCYc_",
        "colab_type": "text"
      },
      "source": [
        "## SGD Linear Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2936OFjzCYc_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "SGD = SGDClassifier()\n",
        "SGD.fit(x_train,y_train)\n",
        "y_pred = SGD.predict(x_val)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NI55NQqQCYdB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "new_index = list(encoder.classes_)\n",
        "new_index.append('accuracy')\n",
        "new_index.append('macro avg')\n",
        "new_index.append('weighted avg')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l0-IPx0DCYdD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CuS0JIdnCYdE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "report = classification_report(y_val, y_pred, output_dict=True)\n",
        "df_sgd_first = pd.DataFrame(report).transpose()\n",
        "df_sgd_first.index = new_index"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "duYnVhVRCYdG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_sgd_first"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G8wjTNd2CYdI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IACqudVfCYdL",
        "colab_type": "text"
      },
      "source": [
        "## SVM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZTEupAHuCYdL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "svm = SVC()\n",
        "svm.fit(x_train,y_train)\n",
        "y_pred = svm.predict(x_val)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r9KGM-kqCYdO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "new_index = list(encoder.classes_)\n",
        "new_index.append('accuracy')\n",
        "new_index.append('macro avg')\n",
        "new_index.append('weighted avg')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R6TMhnifCYdP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "report = classification_report(y_val, y_pred, output_dict=True)\n",
        "df_svm_first = pd.DataFrame(report).transpose()\n",
        "df_svm_first.index = new_index"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wT6SGgYWCYdR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_svm_first"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g6twJQgDCYdT",
        "colab_type": "text"
      },
      "source": [
        "## Grid Search On SVM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "drYzDZCDCYdT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def SVC_GridSearch(X, Y, X_test, Y_test):\n",
        "    svc = SVC()\n",
        "    parameters = {\n",
        "        'C': (0.5,1,2),\n",
        "        'kernel': ('rbf','linear','poly', 'sigmoid'),\n",
        "        'shrinking': (True, False),\n",
        "        'decision_function_shape': ('ovp','ovr'),\n",
        "        \n",
        "\n",
        "    }\n",
        "    grid_search = GridSearchCV(svc, parameters, n_jobs=-1, verbose=0)\n",
        "    grid_search.fit(X, Y)\n",
        "    accuracy = grid_search.best_score_\n",
        "    best_parameters = grid_search.best_estimator_.get_params()\n",
        "    classifier = grid_search.best_estimator_\n",
        "    y_pred = classifier.predict(X_test)\n",
        "    test_accuracy = accuracy_score(y_pred, Y_test)\n",
        "    return best_parameters, accuracy, test_accuracy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bU_51YIICYdV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "best_parameters, accuracy, test_accuracy = SVC_GridSearch(x_train, y_train, x_val, y_val)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oUgciu5PCYdX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bestSVM = SVC()\n",
        "bestSVM.set_params(**best_parameters)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "38eBussyCYdY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bestSVM.fit(x_train,y_train)\n",
        "y_pred = bestSVM.predict(x_val)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GE58l6lyCYdb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "new_index = list(encoder.classes_)\n",
        "new_index.append('accuracy')\n",
        "new_index.append('macro avg')\n",
        "new_index.append('weighted avg')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ygvq84mcCYdc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "report = classification_report(y_val, y_pred, output_dict=True)\n",
        "df_svm = pd.DataFrame(report).transpose()\n",
        "df_svm.index = new_index"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uRxxgboACYde",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_svm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MUaXpVRhCYdf",
        "colab_type": "text"
      },
      "source": [
        "## Vanilla Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qjAjG3ZlCYdf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set the input and output sizes\n",
        "input_size = 40 #NUMBER INPUTS HERE#\n",
        "output_size = 41 #NUMBER OUTPUTS HERE#\n",
        "\n",
        "\n",
        "#DEFINE HIDDEN LAYER SIZE\n",
        "#CAN HAVE MULTIPLE DIFFERENT SIZED LAYERS IF NEEDED\n",
        "#50 NICE START POINT FOR BEING TIME EFFICIENT BUT STILL RELATIVELY COMPLEX\n",
        "hidden_layer_size = 100\n",
        "  \n",
        "\n",
        "#MODEL SPECIFICATIONS\n",
        "model = Sequential([\n",
        "    # tf.keras.layers.Dense is basically implementing: output = activation(dot(input, weight) + bias)\n",
        "    # it takes several arguments, but the most important ones for us are the hidden_layer_size and the activation function\n",
        "    Dense(hidden_layer_size, activation='relu'), # 1st hidden layer\n",
        "    Dropout(0.2),\n",
        "    Dense(hidden_layer_size, activation='relu'), # 2nd hidden layer\n",
        "    Dropout(0.2),\n",
        "    Dense(hidden_layer_size, activation='relu'), # 3rd hidden layer\n",
        "    Dropout(0.2),\n",
        "\n",
        "\n",
        "    # POTENTIALLY MULTIPLE MORE LAYERS HERE #\n",
        "    # NO SINGLE ACTIVATION NECESSARILY BEST (AT THIS STAGE I DO NOT FULLY UNDERSTAND DIFFERENCES, TRY DIFFERENT VARIATIONs)\n",
        "    \n",
        "    # FINAL LAYER MUST TAKE OUTPUT SIZE\n",
        "    #FOR CLASSIFICATION PROBLEMS USE SOFTMAX AS ACTIVATION\n",
        "    Dense(output_size, activation='softmax') # output layer\n",
        "])\n",
        "\n",
        "\n",
        "#COMPILE MODEL GIVING IT OPTIMIZER LOSS FUNCTION AND METRIC OF INTEREST\n",
        "# MOST TIMES USE ADAM FOR OPTIMIZER (LOOK AT OTHERS THOUGH) \n",
        "# lOSS FUNCTION - MANY DIFFERENT VARIATIONS sparse_categorical_crossentropy IS BASICALLY MIN SUM OF SQUARES\n",
        "# TO NOW I AM ONLY INTERESTED IN ACCURACY AT EACH LEVEL (HAVE NOT LOOKED AT OTHER OPTIONS`)\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "###                            ### \n",
        "###                            ###\n",
        "###          TRAINING          ###\n",
        "###                            ###\n",
        "###                            ###\n",
        "\n",
        "# SET SIZE OF BATCHES (FOR SHUFFLING IN PARTS WHEN OVERALL SIZE TO BIG)\n",
        "batch_size = 128\n",
        "\n",
        "# SET MAXIMUM NUMBER OF EPOCHS (JUST SO DOESNT RUN ENDLESSLY)\n",
        "max_epochs = 100\n",
        "\n",
        "# SET EARLY STOPPING FUNCTION\n",
        "# PATIENCE EQUAL 0 (DEFAULT) => STOPS AS SOON AS FOLLOWING EPOCH HAS REDUCED LOSS\n",
        "# PATIENCE EQUAL N => STOPS AFTER N SUBSEQUENT INCREASING LOSSES\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(patience=2)\n",
        "\n",
        "\n",
        "\n",
        "###                            ### \n",
        "###                            ###\n",
        "###         FIT MODEL          ###\n",
        "###                            ###\n",
        "###                            ###\n",
        "\n",
        "model.fit(x_train, # train inputs\n",
        "          y_train, # train targets\n",
        "          batch_size=batch_size, # batch size\n",
        "          epochs=max_epochs, # epochs that we will train for (assuming early stopping doesn't kick in)\n",
        "          callbacks=[early_stopping], # early stopping\n",
        "          validation_data=(x_val, y_val), # validation data\n",
        "          verbose = 1 # shows some information for each epoch so we can analyse\n",
        "          )  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JOyMCmghCYdh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1HxMPMqRCYdj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = model.predict(x_val)\n",
        "y_pred = np.argmax(y_pred, axis=1)\n",
        "vanilla_nn = classification_report(y_val, y_pred)\n",
        "print(vanilla_nn)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AXvweP_-CYdk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5lgo9oYkCYdn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from scipy.stats import skew\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn import linear_model\n",
        "\n",
        "sr = 44100\n",
        "\n",
        "\n",
        "def compute_summ_features(x):\n",
        "    ans = np.hstack((\n",
        "        np.mean(x, axis=1),\n",
        "        np.std(x, axis=1),\n",
        "        skew(x, axis=1),\n",
        "        np.max(x, axis=1),\n",
        "        np.min(x, axis=1)))\n",
        "    return ans\n",
        "\n",
        "\n",
        "def feat_set_1(x, stft):\n",
        "    # Features mentioned in\n",
        "    # - http://aqibsaeed.github.io/2016-09-03-urban-sound-classification-part-1/\n",
        "    # - https://www.kaggle.com/amlanpraharaj/xgb-using-mfcc-opanichev-s-features-lb-0-811\n",
        "\n",
        "    # Mel-scaled power spectrogram\n",
        "    mels = librosa.feature.melspectrogram(x, sr=sr, S=stft)\n",
        "\n",
        "    # Mel-frequency cepstral coefficients\n",
        "    mfccs = librosa.feature.mfcc(y=x, sr=sr, S=stft, n_mfcc=40)\n",
        "\n",
        "    # chorma-stft: Compute a chromagram from a waveform or power spectrogram\n",
        "    chromas = librosa.feature.chroma_stft(S=stft, sr=sr)\n",
        "\n",
        "    # spectral_contrast: Compute spectral contrast\n",
        "    contrasts = librosa.feature.spectral_contrast(x, S=stft, sr=sr)\n",
        "\n",
        "    # Compute roll-off frequency\n",
        "    rolloffs = librosa.feature.spectral_rolloff(x, sr=sr, S=stft)\n",
        "\n",
        "    # Compute the spectral centroid\n",
        "    scentroids = librosa.feature.spectral_centroid(x, sr=sr, S=stft)\n",
        "\n",
        "    # Compute p’th-order spectral bandwidth\n",
        "    bandwidths = librosa.feature.spectral_bandwidth(x, sr=sr, S=stft)\n",
        "\n",
        "    # tonnetz: Computes the tonal centroid features (tonnetz)\n",
        "    tonnetzs = librosa.feature.tonnetz(y=librosa.effects.harmonic(x), sr=sr)\n",
        "\n",
        "    # zero crossing rate\n",
        "    zero_crossing_rates = librosa.feature.zero_crossing_rate(x)\n",
        "\n",
        "    tmp = (mels, mfccs, chromas, contrasts,\n",
        "           rolloffs, scentroids, bandwidths,\n",
        "           tonnetzs, zero_crossing_rates)\n",
        "\n",
        "    ans = np.hstack([\n",
        "        compute_summ_features(x)\n",
        "        for x in tmp\n",
        "    ])\n",
        "\n",
        "    return ans\n",
        "\n",
        "\n",
        "# Features from https://www.kaggle.com/opanichev/lightgbm-baseline\n",
        "def calc_part_features(data, n=2):\n",
        "    ans = []\n",
        "    for j, i in enumerate(range(0, len(data), len(data)//n)):\n",
        "        if j == (n-1):\n",
        "            i = len(data) - 1\n",
        "        if j < n:\n",
        "            ans.append(np.mean(data[i:i + len(data)//n]))\n",
        "            ans.append(np.std(data[i:i + len(data)//n]))\n",
        "            ans.append(np.min(data[i:i + len(data)//n]))\n",
        "            ans.append(np.max(data[i:i + len(data)//n]))\n",
        "    return ans\n",
        "\n",
        "\n",
        "def feat_set_4(x):\n",
        "    abs_data = np.abs(x)\n",
        "    diff_data = np.diff(x)\n",
        "\n",
        "    ans = []\n",
        "\n",
        "    n = 1\n",
        "    ans += calc_part_features(x, n=n)\n",
        "    ans += calc_part_features(abs_data, n=n)\n",
        "    ans += calc_part_features(diff_data, n=n)\n",
        "\n",
        "    n = 2\n",
        "    ans += calc_part_features(x, n=n)\n",
        "    ans += calc_part_features(abs_data, n=n)\n",
        "    ans += calc_part_features(diff_data, n=n)\n",
        "\n",
        "    n = 3\n",
        "    ans += calc_part_features(x, n=n)\n",
        "    ans += calc_part_features(abs_data, n=n)\n",
        "    ans += calc_part_features(diff_data, n=n)\n",
        "\n",
        "    return np.array(ans)\n",
        "\n",
        "\n",
        "# Features from https://www.kaggle.com/agehsbarg/audio-challenge-cnn-with-concatenated-inputs\n",
        "def get_spectra_win(y, L, N):\n",
        "    dft = np.fft.fft(y)\n",
        "    fl = np.abs(dft)\n",
        "    xf = np.arange(0.0, N/L, 1/L)\n",
        "    return (xf, fl)\n",
        "\n",
        "\n",
        "def get_spectra(signal, fs, M=1000, sM=500):\n",
        "\n",
        "    N = signal.shape[0]\n",
        "    ind = np.arange(100, N, M)\n",
        "\n",
        "    spectra = []\n",
        "    meanspectrum = np.repeat(0, M)\n",
        "\n",
        "    for k in range(1, len(ind)):\n",
        "        n1 = ind[k-1]\n",
        "        n2 = ind[k]\n",
        "        y = signal[n1:n2]\n",
        "        L = (n2-n1)/fs\n",
        "        N = n2-n1\n",
        "        (xq, fq) = get_spectra_win(y, L, N)\n",
        "        spectra.append(fq)\n",
        "\n",
        "    spectra = pd.DataFrame(spectra)\n",
        "    meanspectrum = spectra.apply(lambda x: np.log(1+np.mean(x)), axis=0)\n",
        "    stdspectrum = spectra.apply(lambda x: np.log(1+np.std(x)), axis=0)\n",
        "\n",
        "    meanspectrum = meanspectrum[0:sM]\n",
        "    stdspectrum = stdspectrum[0:sM]\n",
        "\n",
        "    return (meanspectrum, stdspectrum)\n",
        "\n",
        "\n",
        "def get_width(w):\n",
        "    if np.sum(w) == 0:\n",
        "        return [0, 0, 0]\n",
        "    else:\n",
        "        z = np.diff(np.where(np.insert(np.append(w, 0), 0, 0) == 0))-1\n",
        "        z = z[z > 0]\n",
        "    return [np.log(1+np.mean(z)),\n",
        "            np.log(1+np.std(z)),\n",
        "            np.log(1+np.max(z)),\n",
        "            len(z)]\n",
        "\n",
        "\n",
        "def running_mean(x, N):\n",
        "    cumsum = np.cumsum(np.insert(x, 0, 0))\n",
        "    return (cumsum[N:] - cumsum[:-N]) / float(N)\n",
        "\n",
        "\n",
        "# predictors related to peaks\n",
        "def num_peaks(x):\n",
        "    x = np.array(x[0:len(x)])\n",
        "    n10 = np.sum(x > 0.10*np.max(x))\n",
        "    n20 = np.sum(x > 0.20*np.max(x))\n",
        "    n50 = np.sum(x > 0.50*np.max(x))\n",
        "    n90 = np.sum(x > 0.90*np.max(x))\n",
        "    n99 = np.sum(x > 0.99*np.max(x))\n",
        "    lead_min = np.min(np.where(x == np.max(x)))\n",
        "    w10 = get_width(1*(x > 0.10*np.max(x)))\n",
        "    w20 = get_width(1*(x > 0.20*np.max(x)))\n",
        "    w50 = get_width(1*(x > 0.50*np.max(x)))\n",
        "    w90 = get_width(1*(x > 0.90*np.max(x)))\n",
        "    w99 = get_width(1*(x > 0.99*np.max(x)))\n",
        "    W = w10+w20+w50+w90+w99\n",
        "\n",
        "    f_sc = np.sum(np.arange(0, len(x))*(x*x)/np.sum(x*x))\n",
        "\n",
        "    i1 = np.where(x < 0.10*np.max(x))[0]\n",
        "    if i1.size == 0:\n",
        "        lincoef_w = [0, 0, 0]\n",
        "    else:\n",
        "        a1 = i1[i1 < lead_min]\n",
        "        a2 = i1[i1 > lead_min]\n",
        "\n",
        "        if a1.size == 0:\n",
        "            i1_left = 0\n",
        "        else:\n",
        "            i1_left = np.max(i1[i1 < lead_min])\n",
        "        if a2.size == 0:\n",
        "            i1_right = 0\n",
        "        else:\n",
        "            i1_right = np.min(i1[i1 > lead_min])\n",
        "\n",
        "        lead_min_width = i1_right - i1_left\n",
        "        if (lead_min_width > 2):\n",
        "            poly_w = PolynomialFeatures(degree=2, include_bias=False)\n",
        "            f_ind_w = poly_w.fit_transform(\n",
        "                np.arange(i1_left, i1_right, 1).reshape(-1, 1))\n",
        "            clf_w = linear_model.LinearRegression()\n",
        "            linmodel_w = clf_w.fit(f_ind_w, np.array(x[i1_left:i1_right]))\n",
        "            lincoef_w = list(linmodel_w.coef_)+[linmodel_w.intercept_]\n",
        "        else:\n",
        "            lincoef_w = [0, 0, 0]\n",
        "\n",
        "    S = np.sum(x)\n",
        "    S_n = np.sum(x)/len(x)\n",
        "    S2 = np.sqrt(np.sum(x*x))\n",
        "    S2_n = np.sqrt(np.sum(x*x))/len(x)\n",
        "    integrals = [S, S_n, S2, S2_n]\n",
        "\n",
        "    poly = PolynomialFeatures(degree=2, include_bias=False)\n",
        "    f_ind = poly.fit_transform(np.arange(0, len(x)).reshape(-1, 1))\n",
        "    clf = linear_model.LinearRegression()\n",
        "    linmodel = clf.fit(f_ind, x)\n",
        "    lincoef_spectrum = list(linmodel.coef_)+[linmodel.intercept_]\n",
        "\n",
        "    high_freq_sum_50 = np.sum(x[0:50] >= 0.5*np.max(x))\n",
        "    high_freq_sum_90 = np.sum(x[0:50] >= 0.9*np.max(x))\n",
        "\n",
        "    r = [f_sc, n10, n20, n50, n90, n99,\n",
        "         lead_min, high_freq_sum_50, high_freq_sum_90] \\\n",
        "        + W + lincoef_spectrum + integrals + lincoef_w\n",
        "    return r\n",
        "\n",
        "\n",
        "def runningMeanFast(x, N=20):\n",
        "    return np.convolve(x, np.ones((N,))/N)[(N-1):]\n",
        "\n",
        "\n",
        "def feat_set_2(x):\n",
        "    rawsignal = x\n",
        "    rawsignal_sq = rawsignal*rawsignal\n",
        "    silenced = []\n",
        "    sound = []\n",
        "    attack = []\n",
        "    for wd in [2000]:\n",
        "        rawsignal_sq_rm = running_mean(rawsignal_sq, wd)\n",
        "        w1 = 1*(rawsignal_sq_rm < 0.01*np.max(rawsignal_sq_rm))\n",
        "        silenced = silenced + get_width(w1)\n",
        "        w2 = 1*(rawsignal_sq_rm < 0.05*np.max(rawsignal_sq_rm))\n",
        "        silenced = silenced + get_width(w2)\n",
        "        w3 = 1*(rawsignal_sq_rm > 0.05*np.max(rawsignal_sq_rm))\n",
        "        sound = sound + get_width(w3)\n",
        "        w4 = 1*(rawsignal_sq_rm > 0.25*np.max(rawsignal_sq_rm))\n",
        "        sound = sound + get_width(w4)\n",
        "        time_to_attack = np.min(np.where(\n",
        "            rawsignal_sq_rm > 0.99*np.max(rawsignal_sq_rm)))\n",
        "        time_rel = np.where(rawsignal_sq_rm < 0.2*np.max(rawsignal_sq_rm))[0]\n",
        "        if (time_rel.size == 0):\n",
        "            time_to_relax = len(rawsignal_sq_rm)\n",
        "        elif (time_rel[time_rel > time_to_attack].size == 0):\n",
        "            time_to_relax = len(rawsignal_sq_rm)\n",
        "        else:\n",
        "            time_to_relax = np.min(time_rel[time_rel > time_to_attack])\n",
        "        attack.append(np.log(1+time_to_attack))\n",
        "        attack.append(np.log(1+time_to_relax))\n",
        "\n",
        "    lr = len(rawsignal)\n",
        "    zerocross_tot = np.log(\n",
        "        1 + np.sum(\n",
        "            np.array(\n",
        "                rawsignal[0:(lr-1)]\n",
        "            ) * np.array(rawsignal[1:lr]) <= 0))\n",
        "    zerocross_prop = np.sum(\n",
        "        np.array(\n",
        "            rawsignal[0:(lr-1)]) * np.array(rawsignal[1:lr]) <= 0) / lr\n",
        "    return np.array(sound + attack + [zerocross_tot, zerocross_prop])\n",
        "\n",
        "\n",
        "def feat_set_3(x):\n",
        "    (m, sd) = get_spectra(x, sr, 2000, 1000)\n",
        "    ans1 = np.array(num_peaks(m))\n",
        "    ans2 = (lambda x: x[np.arange(0, len(x), 40)])(np.array(runningMeanFast(m)))\n",
        "    return np.concatenate((ans1, ans2))\n",
        "\n",
        "\n",
        "def all_feats(filename):\n",
        "    x = np.load(filename)\n",
        "    stft = np.abs(librosa.stft(x))\n",
        "    out1 = feat_set_1(x, stft=stft)\n",
        "    out2 = feat_set_2(x)\n",
        "    out3 = feat_set_3(x)\n",
        "    out4 = feat_set_4(x)\n",
        "\n",
        "    assert out1.shape[0] == 985\n",
        "    assert out2.shape[0] == 12\n",
        "    assert out3.shape[0] == 64\n",
        "    assert out4.shape[0] == 72\n",
        "\n",
        "    return np.concatenate((\n",
        "        out1, out2, out3, out4\n",
        "    ))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lBuLCd-I1OTG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
